{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea2d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Pyfhel.util import ENCODING_t\n",
    "from Pyfhel import PyCtxt, Pyfhel, PyPtxt\n",
    "import torch\n",
    "from torch import nn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed8b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyfhel = Pyfhel()\n",
    "pyfhel.contextGen(p=65537, m=16384, base=2, sec=128, intDigits=64, fracDigits = 32)\n",
    "pyfhel.keyGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9060d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyfhel.relinKeyGen(32,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea27a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApproximateSigmoid(nn.Module):\n",
    "    def forward(self,x,pyfhel=None):\n",
    "        if type(x) == list or type(x) == PyCtxt:\n",
    "            with torch.no_grad():\n",
    "                return self.forward_encrypted(x,pyfhel)\n",
    "        else:\n",
    "            # f3(x) = 0.5 + 1.20096(x/8) - 0.81562(x/8)^3\n",
    "            return 0.5 + 1.20096*(x/8) - 0.81562*((x/8)**3)\n",
    "    \n",
    "    def forward_encrypted(self,x,pyfhel):\n",
    "        assert type(pyfhel) == Pyfhel\n",
    "        if type(x) == list:\n",
    "            return [self.forward_encrypred_single(a,pyfhel) for a in x]\n",
    "        else:\n",
    "            return self.forward_encrypred_single(x,pyfhel)\n",
    "    \n",
    "    def forward_encrypred_single(self,a,pyfhel):\n",
    "        term_1 = pyfhel.encode(0.5)\n",
    "        a_by_8 = pyfhel.multiply_plain(a,pyfhel.encode(0.125),in_new_ctxt=True)\n",
    "        term_2 = pyfhel.multiply_plain(a_by_8,pyfhel.encode(1.20096),in_new_ctxt=True)\n",
    "        a_by_8_cube = pyfhel.power(a_by_8,3,in_new_ctxt=True)\n",
    "        pyfhel.relinearize(a_by_8_cube)\n",
    "        term_3 = pyfhel.multiply_plain(a_by_8_cube,pyfhel.encode(- 0.81562),in_new_ctxt=True)\n",
    "        pyfhel.add(term_2,term_3)\n",
    "        pyfhel.add_plain(term_2,term_1)\n",
    "        return term_2\n",
    "\n",
    "class ModifiedLinear(nn.Linear):\n",
    "    def forward(self,x,pyfhel=None):\n",
    "        if type(x) == list or type(x) == PyCtxt:\n",
    "            with torch.no_grad():\n",
    "                return self.forward_encrypted(x,pyfhel)\n",
    "        else:\n",
    "            return super().forward(x)\n",
    "    \n",
    "    def forward_encrypted(self,x,pyfhel):\n",
    "        assert type(pyfhel) == Pyfhel\n",
    "        assert type(x) == list # no support for batching right now \n",
    "        outputs = []\n",
    "        weights = self.weight.detach().numpy()\n",
    "        biases = self.bias.detach().numpy()\n",
    "        for row,bias in zip(weights,biases):\n",
    "            out = pyfhel.encryptFrac(bias)\n",
    "            assert len(row) == len(x)\n",
    "            for weight_element,input_element in zip(row,x):\n",
    "                weight_input_product = pyfhel.multiply_plain(input_element,pyfhel.encode(weight_element),in_new_ctxt=True)\n",
    "                pyfhel.relinearize(weight_input_product)\n",
    "                pyfhel.add(out,weight_input_product)\n",
    "            outputs.append(out)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc49bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedSequential(nn.Sequential):\n",
    "    def forward(self,x,pyfhel=None):\n",
    "        if type(x) == torch.Tensor:\n",
    "            return super().forward(x)\n",
    "        return self.forward_encrypted(x,pyfhel)\n",
    "    \n",
    "    def forward_encrypted(self,x,pyfhel):\n",
    "        for child in self.children():\n",
    "            x = child(x,pyfhel)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "414e6072",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 4\n",
    "HIDDEN_SIZE = 2\n",
    "OUTPUT_SIZE = 1\n",
    "\n",
    "# creating a neural network which can handle \n",
    "encrpyted_neural_processor = ModifiedSequential(\n",
    "    ModifiedLinear(INPUT_SIZE,HIDDEN_SIZE),\n",
    "    ApproximateSigmoid(),\n",
    "    ModifiedLinear(HIDDEN_SIZE,OUTPUT_SIZE),\n",
    "    ApproximateSigmoid()\n",
    ")\n",
    "\n",
    "# correspoing pytorch model initialization would look like this:\n",
    "traditional_neural_network = nn.Sequential(\n",
    "    nn.Linear(INPUT_SIZE,HIDDEN_SIZE),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(HIDDEN_SIZE,OUTPUT_SIZE),\n",
    "    nn.Sigmoid()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "40d245af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the perceptron on IRIS dataset\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "\n",
    "mask = y<=1\n",
    "\n",
    "X=X[mask]\n",
    "y=y[mask]\n",
    "\n",
    "# need this to normalize inputs later\n",
    "maxes = np.max(X,axis=0)\n",
    "\n",
    "X = X/maxes\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "X = torch.tensor(X,dtype=torch.float)\n",
    "y = torch.tensor(y,dtype=torch.float)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f4ea228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0:'setosa', 1:'versicolor'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e063739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(encrpyted_neural_processor.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02e5d49",
   "metadata": {},
   "source": [
    "## The model trains on unencrypted data but may predict on both: encrypted and unencrypted data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0e7a360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after 0 epochs is 55.58208787441254\n",
      "loss after 5 epochs is 43.32298055291176\n",
      "loss after 10 epochs is 16.029682844877243\n",
      "loss after 15 epochs is 2.0014456705539487\n",
      "loss after 20 epochs is 0.8141750950017013\n",
      "loss after 25 epochs is 0.4686754490248859\n",
      "loss after 30 epochs is 0.281995673525671\n",
      "loss after 35 epochs is 0.18029425293207169\n",
      "loss after 40 epochs is 0.10111747030168772\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 45\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for a_x,a_y in zip(X_train,y_train):\n",
    "        a_out = encrpyted_neural_processor(a_x)\n",
    "        a_out.clip_(0,1)\n",
    "        a_loss = loss(a_out,a_y)\n",
    "        total_loss += a_loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        a_loss.backward()\n",
    "        optimizer.step()\n",
    "    if i%5 == 0:\n",
    "        print(f'loss after {i} epochs is {total_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3517b3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1020, 0.1860, 0.0538, 0.0617])\n"
     ]
    }
   ],
   "source": [
    "# the model is now trained. Let's try out a test with both: encrypted and unencrypted data\n",
    "\n",
    "# first, lets prepare unencrypted input\n",
    "unencrypted_input = (X_test/maxes)[1].float()\n",
    "\n",
    "print(unencrypted_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "28347e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Pyfhel Ciphertext at 0x7f17e2036f80, encoding=FRACTIONAL, size=2/2, noiseBudget=410>, <Pyfhel Ciphertext at 0x7f17e2038b80, encoding=FRACTIONAL, size=2/2, noiseBudget=410>, <Pyfhel Ciphertext at 0x7f17e2e91900, encoding=FRACTIONAL, size=2/2, noiseBudget=410>, <Pyfhel Ciphertext at 0x7f17e20339c0, encoding=FRACTIONAL, size=2/2, noiseBudget=410>]\n"
     ]
    }
   ],
   "source": [
    "# Lets also prepare encrypted input\n",
    "encrpyted_input = [pyfhel.encryptFrac(a_inp.item()) for a_inp in unencrypted_input]\n",
    "\n",
    "print(encrpyted_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4096e1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0330], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encrpyted_neural_processor(unencrypted_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "75a0a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "encrpyted_output = encrpyted_neural_processor(encrpyted_input,pyfhel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "be942dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.033422748325392604"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyfhel.decryptFrac(encrpyted_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f89481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
